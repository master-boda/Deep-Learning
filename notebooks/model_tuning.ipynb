{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Tuning Notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda\n",
    "import tensorflow as tf\n",
    "\n",
    "def clear_gpu_memory():\n",
    "    device = cuda.get_current_device()\n",
    "    device.reset() # dump the memory contents to free up the memory (it accumulates over the session)\n",
    "    \n",
    "# CUDA (Nvidia GPU Computing)\n",
    "if len(tf.config.list_physical_devices('GPU')) > 0:\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    print(\"Num GPUs Available: \", len(gpus))\n",
    "    \n",
    "    clear_gpu_memory()\n",
    "    \n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "\n",
    "    tf.config.set_logical_device_configuration(\n",
    "    gpus[0], \n",
    "    [tf.config.LogicalDeviceConfiguration(memory_limit=8192)])  # limit to 4GB\n",
    "\n",
    "    tf.compat.v1.disable_eager_execution()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from src.models.models import *\n",
    "from src.utils.modeling import *\n",
    "from src.utils.preproc import *\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: d:\\deep_learning_project CWD: d:\\deep_learning_project\n"
     ]
    }
   ],
   "source": [
    "# because the utils in the src are designed to be run from the root of the project,\n",
    "# and by default jupyter runs from the notebook directory we need to change the working directory to the root\n",
    "\n",
    "def find_project_root(filename=\".git\"): # .git is located in the root of the project\n",
    "    current_dir = os.getcwd()\n",
    "    while current_dir != os.path.dirname(current_dir): # stops only when at the root (moves up 1 level each iteration)\n",
    "        if filename in os.listdir(current_dir):\n",
    "            return current_dir\n",
    "        current_dir = os.path.dirname(current_dir)\n",
    "\n",
    "project_root = find_project_root()\n",
    "os.chdir(project_root)  # change the working directory to the project root\n",
    "\n",
    "print(\"Project root:\", project_root, \"CWD:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Binary Classification Models Fine-Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Traditional**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pre-Trained**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VGG 16**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_classification_vgg16_model(input_shape):\n",
    "    \n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    \n",
    "    # train some layers and freeze others\n",
    "    for layer in base_model.layers[:-4]:\n",
    "        layer.trainable = False\n",
    "    for layer in base_model.layers[-4:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(base_model)\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # low learning rate for fine tuning\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "44/44 [==============================] - ETA: 0s - batch: 21.5000 - size: 32.0000 - loss: 0.6080 - accuracy: 0.6619"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vic\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training_v1.py:2332: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 58s 569ms/step - batch: 21.5000 - size: 32.0000 - loss: 0.6080 - accuracy: 0.6619 - val_loss: 0.5586 - val_accuracy: 0.6755\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - 17s 366ms/step - batch: 21.5000 - size: 32.0000 - loss: 0.4588 - accuracy: 0.7663 - val_loss: 0.3790 - val_accuracy: 0.8146\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - 16s 356ms/step - batch: 21.5000 - size: 32.0000 - loss: 0.4083 - accuracy: 0.8132 - val_loss: 0.5486 - val_accuracy: 0.7053\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - 17s 370ms/step - batch: 21.5000 - size: 32.0000 - loss: 0.2893 - accuracy: 0.8736 - val_loss: 0.2648 - val_accuracy: 0.8775\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - 16s 350ms/step - batch: 21.5000 - size: 32.0000 - loss: 0.3044 - accuracy: 0.8636 - val_loss: 0.2750 - val_accuracy: 0.8642\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - 16s 358ms/step - batch: 21.5000 - size: 32.0000 - loss: 0.2395 - accuracy: 0.8949 - val_loss: 0.2801 - val_accuracy: 0.8808\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - 16s 350ms/step - batch: 21.5000 - size: 32.0000 - loss: 0.2072 - accuracy: 0.9134 - val_loss: 0.2549 - val_accuracy: 0.9040\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - 16s 355ms/step - batch: 21.5000 - size: 32.0000 - loss: 0.1727 - accuracy: 0.9318 - val_loss: 0.3699 - val_accuracy: 0.8907\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - 17s 361ms/step - batch: 21.5000 - size: 32.0000 - loss: 0.2755 - accuracy: 0.8842 - val_loss: 0.2384 - val_accuracy: 0.9139\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - 16s 345ms/step - batch: 21.5000 - size: 32.0000 - loss: 0.1757 - accuracy: 0.9276 - val_loss: 0.2762 - val_accuracy: 0.8874\n",
      "Test loss:  0.41194572629073994\n",
      "Test accuracy:  0.8576159\n"
     ]
    }
   ],
   "source": [
    "if len(tf.config.list_physical_devices('GPU')) > 0:\n",
    "    clear_gpu_memory()\n",
    "\n",
    "train_gen, val_gen, X_test, y_test, class_weights = preproc_pipeline(desired_magnification='200X', \n",
    "                                                    image_resolution=(224, 224), \n",
    "                                                    classification_type='binary')\n",
    "\n",
    "vgg16 = binary_classification_vgg16_model((224, 224, 3))\n",
    "\n",
    "fitted_vgg16 = train_model(train_gen, val_gen, vgg16, class_weights=class_weights, epochs=10)\n",
    "\n",
    "test_loss, test_acc = fitted_vgg16.evaluate(X_test, y_test)\n",
    "print(f'Test loss: ', test_loss)\n",
    "print(f'Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> Data augmentation clearly improves the model's performance. </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_classification_vgg16_model(input_shape):\n",
    "    \n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    \n",
    "    # train some layers and freeze others\n",
    "    for layer in base_model.layers[:-7]:\n",
    "        layer.trainable = False\n",
    "    for layer in base_model.layers[-7:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(base_model)\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "    \n",
    "    # low learning rate for fine tuning\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images before data augmentation: 1408\n",
      "Number of training images after data augmentation: 9856\n",
      "Epoch 1/30\n",
      "308/308 [==============================] - ETA: 0s - batch: 153.5000 - size: 32.0000 - loss: 1.7375 - accuracy: 0.2993"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vic\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training_v1.py:2332: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308/308 [==============================] - 199s 492ms/step - batch: 153.5000 - size: 32.0000 - loss: 1.7375 - accuracy: 0.2993 - val_loss: 1.6420 - val_accuracy: 0.3742\n",
      "Epoch 2/30\n",
      "308/308 [==============================] - 144s 466ms/step - batch: 153.5000 - size: 32.0000 - loss: 1.0866 - accuracy: 0.5148 - val_loss: 1.2366 - val_accuracy: 0.5232\n",
      "Epoch 3/30\n",
      "308/308 [==============================] - 147s 472ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.7633 - accuracy: 0.6423 - val_loss: 0.9014 - val_accuracy: 0.6490\n",
      "Epoch 4/30\n",
      "308/308 [==============================] - 152s 491ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.6147 - accuracy: 0.7111 - val_loss: 0.6449 - val_accuracy: 0.7152\n",
      "Epoch 5/30\n",
      "308/308 [==============================] - 176s 569ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.4997 - accuracy: 0.7468 - val_loss: 0.7463 - val_accuracy: 0.7417\n",
      "Epoch 6/30\n",
      "308/308 [==============================] - 189s 612ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.4078 - accuracy: 0.7911 - val_loss: 0.6280 - val_accuracy: 0.7781\n",
      "Epoch 7/30\n",
      "308/308 [==============================] - 182s 590ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.3839 - accuracy: 0.8019 - val_loss: 0.5924 - val_accuracy: 0.7682\n",
      "Epoch 8/30\n",
      "308/308 [==============================] - 180s 582ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.2588 - accuracy: 0.8580 - val_loss: 0.6342 - val_accuracy: 0.8245\n",
      "Epoch 9/30\n",
      "308/308 [==============================] - 181s 586ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.2862 - accuracy: 0.8545 - val_loss: 0.5907 - val_accuracy: 0.8079\n",
      "Epoch 10/30\n",
      "308/308 [==============================] - 179s 578ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.2905 - accuracy: 0.8570 - val_loss: 0.8809 - val_accuracy: 0.7715\n",
      "Epoch 11/30\n",
      "308/308 [==============================] - 179s 579ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.2134 - accuracy: 0.8800 - val_loss: 0.6690 - val_accuracy: 0.8146\n",
      "Epoch 12/30\n",
      "308/308 [==============================] - 179s 576ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.1782 - accuracy: 0.8985 - val_loss: 0.6274 - val_accuracy: 0.8344\n",
      "Epoch 13/30\n",
      "308/308 [==============================] - 181s 585ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.2152 - accuracy: 0.8917 - val_loss: 0.5037 - val_accuracy: 0.8477\n",
      "Epoch 14/30\n",
      "308/308 [==============================] - 180s 582ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.1513 - accuracy: 0.9144 - val_loss: 0.6006 - val_accuracy: 0.8344\n",
      "Epoch 15/30\n",
      "308/308 [==============================] - 181s 583ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.1698 - accuracy: 0.9140 - val_loss: 0.6681 - val_accuracy: 0.8013\n",
      "Epoch 16/30\n",
      "308/308 [==============================] - 178s 574ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.1710 - accuracy: 0.9120 - val_loss: 0.7433 - val_accuracy: 0.8179\n",
      "Epoch 17/30\n",
      "308/308 [==============================] - 180s 581ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.1173 - accuracy: 0.9301 - val_loss: 0.8129 - val_accuracy: 0.8377\n",
      "Epoch 18/30\n",
      "308/308 [==============================] - 180s 581ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.1604 - accuracy: 0.9199 - val_loss: 0.6222 - val_accuracy: 0.8775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vic\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        16\n",
      "           1       0.96      0.85      0.90       135\n",
      "           2       0.87      0.85      0.86        39\n",
      "           3       0.65      0.88      0.75        25\n",
      "           4       0.81      0.83      0.82        30\n",
      "           5       0.79      0.95      0.86        20\n",
      "           6       0.69      0.69      0.69        16\n",
      "           7       0.91      1.00      0.95        21\n",
      "\n",
      "    accuracy                           0.86       302\n",
      "   macro avg       0.83      0.87      0.85       302\n",
      "weighted avg       0.88      0.86      0.87       302\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_gen, val_gen, X_test, y_test, class_weights = preproc_pipeline(desired_magnification='200X', \n",
    "                                                    image_resolution=(224, 224), \n",
    "                                                    classification_type='multiclass',\n",
    "                                                    use_data_augmentation=True,\n",
    "                                                    augmented_images_per_image=6)\n",
    "\n",
    "vgg16 = multiclass_classification_vgg16_model((224, 224, 3))\n",
    "\n",
    "fitted_vgg16 = train_model(train_gen, val_gen, vgg16, class_weights=class_weights, epochs=30, early_stopping_patience=5)\n",
    "\n",
    "get_classification_report(fitted_vgg16, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
