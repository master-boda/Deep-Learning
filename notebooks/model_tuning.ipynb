{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Tuning Notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda\n",
    "import tensorflow as tf\n",
    "\n",
    "def clear_gpu_memory():\n",
    "    device = cuda.get_current_device()\n",
    "    device.reset() # dump the memory contents to free up the memory (it accumulates over the session)\n",
    "    \n",
    "# CUDA (Nvidia GPU Computing)\n",
    "if len(tf.config.list_physical_devices('GPU')) > 0:\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    print(\"Num GPUs Available: \", len(gpus))\n",
    "    \n",
    "    clear_gpu_memory()\n",
    "    \n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "\n",
    "    tf.config.set_logical_device_configuration(\n",
    "    gpus[0], \n",
    "    [tf.config.LogicalDeviceConfiguration(memory_limit=8192)])  # limit to 4GB\n",
    "\n",
    "    tf.compat.v1.disable_eager_execution()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from src.models.models import *\n",
    "from src.utils.modeling import *\n",
    "from src.utils.preproc import *\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: d:\\deep_learning_project CWD: d:\\deep_learning_project\n"
     ]
    }
   ],
   "source": [
    "# because the utils in the src are designed to be run from the root of the project,\n",
    "# and by default jupyter runs from the notebook directory we need to change the working directory to the root\n",
    "\n",
    "def find_project_root(filename=\".git\"): # .git is located in the root of the project\n",
    "    current_dir = os.getcwd()\n",
    "    while current_dir != os.path.dirname(current_dir): # stops only when at the root (moves up 1 level each iteration)\n",
    "        if filename in os.listdir(current_dir):\n",
    "            return current_dir\n",
    "        current_dir = os.path.dirname(current_dir)\n",
    "\n",
    "project_root = find_project_root()\n",
    "os.chdir(project_root)  # change the working directory to the project root\n",
    "\n",
    "print(\"Project root:\", project_root, \"CWD:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Binary Classification Models Fine-Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Traditional**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pre-Trained**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VGG 16**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_classification_vgg16_model(input_shape):\n",
    "    \n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    \n",
    "    # train some layers and freeze others\n",
    "    for layer in base_model.layers[:-4]:\n",
    "        layer.trainable = False\n",
    "    for layer in base_model.layers[-4:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(base_model)\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # low learning rate for fine tuning\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "44/44 [==============================] - ETA: 0s - batch: 21.5000 - size: 32.0000 - loss: 0.6080 - accuracy: 0.6619"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vic\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training_v1.py:2332: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 58s 569ms/step - batch: 21.5000 - size: 32.0000 - loss: 0.6080 - accuracy: 0.6619 - val_loss: 0.5586 - val_accuracy: 0.6755\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - 17s 366ms/step - batch: 21.5000 - size: 32.0000 - loss: 0.4588 - accuracy: 0.7663 - val_loss: 0.3790 - val_accuracy: 0.8146\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - 16s 356ms/step - batch: 21.5000 - size: 32.0000 - loss: 0.4083 - accuracy: 0.8132 - val_loss: 0.5486 - val_accuracy: 0.7053\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - 17s 370ms/step - batch: 21.5000 - size: 32.0000 - loss: 0.2893 - accuracy: 0.8736 - val_loss: 0.2648 - val_accuracy: 0.8775\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - 16s 350ms/step - batch: 21.5000 - size: 32.0000 - loss: 0.3044 - accuracy: 0.8636 - val_loss: 0.2750 - val_accuracy: 0.8642\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - 16s 358ms/step - batch: 21.5000 - size: 32.0000 - loss: 0.2395 - accuracy: 0.8949 - val_loss: 0.2801 - val_accuracy: 0.8808\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - 16s 350ms/step - batch: 21.5000 - size: 32.0000 - loss: 0.2072 - accuracy: 0.9134 - val_loss: 0.2549 - val_accuracy: 0.9040\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - 16s 355ms/step - batch: 21.5000 - size: 32.0000 - loss: 0.1727 - accuracy: 0.9318 - val_loss: 0.3699 - val_accuracy: 0.8907\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - 17s 361ms/step - batch: 21.5000 - size: 32.0000 - loss: 0.2755 - accuracy: 0.8842 - val_loss: 0.2384 - val_accuracy: 0.9139\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - 16s 345ms/step - batch: 21.5000 - size: 32.0000 - loss: 0.1757 - accuracy: 0.9276 - val_loss: 0.2762 - val_accuracy: 0.8874\n",
      "Test loss:  0.41194572629073994\n",
      "Test accuracy:  0.8576159\n"
     ]
    }
   ],
   "source": [
    "if len(tf.config.list_physical_devices('GPU')) > 0:\n",
    "    clear_gpu_memory()\n",
    "\n",
    "train_gen, val_gen, test_gen, class_weights = preproc_pipeline(desired_magnification='200X', \n",
    "                                                    image_resolution=(224, 224), \n",
    "                                                    classification_type='binary')\n",
    "\n",
    "vgg16 = binary_classification_vgg16_model((224, 224, 3))\n",
    "\n",
    "fitted_vgg16 = train_model(train_gen, val_gen, vgg16, class_weights=class_weights, epochs=10)\n",
    "\n",
    "test_loss, test_acc = fitted_vgg16.evaluate(X_test, y_test)\n",
    "print(f'Test loss: ', test_loss)\n",
    "print(f'Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> Data augmentation clearly improves the model's performance. </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_classification_vgg16_model(input_shape):\n",
    "    \n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    \n",
    "    # train some layers and freeze others\n",
    "    for layer in base_model.layers[:-7]:\n",
    "        layer.trainable = False\n",
    "    for layer in base_model.layers[-7:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(base_model)\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "    \n",
    "    # low learning rate for fine tuning\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images before data augmentation: 1408\n",
      "Number of training images after data augmentation: 9856\n",
      "Epoch 1/30\n",
      "308/308 [==============================] - ETA: 0s - batch: 153.5000 - size: 32.0000 - loss: 1.7375 - accuracy: 0.2993"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vic\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training_v1.py:2332: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308/308 [==============================] - 199s 492ms/step - batch: 153.5000 - size: 32.0000 - loss: 1.7375 - accuracy: 0.2993 - val_loss: 1.6420 - val_accuracy: 0.3742\n",
      "Epoch 2/30\n",
      "308/308 [==============================] - 144s 466ms/step - batch: 153.5000 - size: 32.0000 - loss: 1.0866 - accuracy: 0.5148 - val_loss: 1.2366 - val_accuracy: 0.5232\n",
      "Epoch 3/30\n",
      "308/308 [==============================] - 147s 472ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.7633 - accuracy: 0.6423 - val_loss: 0.9014 - val_accuracy: 0.6490\n",
      "Epoch 4/30\n",
      "308/308 [==============================] - 152s 491ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.6147 - accuracy: 0.7111 - val_loss: 0.6449 - val_accuracy: 0.7152\n",
      "Epoch 5/30\n",
      "308/308 [==============================] - 176s 569ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.4997 - accuracy: 0.7468 - val_loss: 0.7463 - val_accuracy: 0.7417\n",
      "Epoch 6/30\n",
      "308/308 [==============================] - 189s 612ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.4078 - accuracy: 0.7911 - val_loss: 0.6280 - val_accuracy: 0.7781\n",
      "Epoch 7/30\n",
      "308/308 [==============================] - 182s 590ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.3839 - accuracy: 0.8019 - val_loss: 0.5924 - val_accuracy: 0.7682\n",
      "Epoch 8/30\n",
      "308/308 [==============================] - 180s 582ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.2588 - accuracy: 0.8580 - val_loss: 0.6342 - val_accuracy: 0.8245\n",
      "Epoch 9/30\n",
      "308/308 [==============================] - 181s 586ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.2862 - accuracy: 0.8545 - val_loss: 0.5907 - val_accuracy: 0.8079\n",
      "Epoch 10/30\n",
      "308/308 [==============================] - 179s 578ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.2905 - accuracy: 0.8570 - val_loss: 0.8809 - val_accuracy: 0.7715\n",
      "Epoch 11/30\n",
      "308/308 [==============================] - 179s 579ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.2134 - accuracy: 0.8800 - val_loss: 0.6690 - val_accuracy: 0.8146\n",
      "Epoch 12/30\n",
      "308/308 [==============================] - 179s 576ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.1782 - accuracy: 0.8985 - val_loss: 0.6274 - val_accuracy: 0.8344\n",
      "Epoch 13/30\n",
      "308/308 [==============================] - 181s 585ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.2152 - accuracy: 0.8917 - val_loss: 0.5037 - val_accuracy: 0.8477\n",
      "Epoch 14/30\n",
      "308/308 [==============================] - 180s 582ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.1513 - accuracy: 0.9144 - val_loss: 0.6006 - val_accuracy: 0.8344\n",
      "Epoch 15/30\n",
      "308/308 [==============================] - 181s 583ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.1698 - accuracy: 0.9140 - val_loss: 0.6681 - val_accuracy: 0.8013\n",
      "Epoch 16/30\n",
      "308/308 [==============================] - 178s 574ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.1710 - accuracy: 0.9120 - val_loss: 0.7433 - val_accuracy: 0.8179\n",
      "Epoch 17/30\n",
      "308/308 [==============================] - 180s 581ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.1173 - accuracy: 0.9301 - val_loss: 0.8129 - val_accuracy: 0.8377\n",
      "Epoch 18/30\n",
      "308/308 [==============================] - 180s 581ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.1604 - accuracy: 0.9199 - val_loss: 0.6222 - val_accuracy: 0.8775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vic\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        16\n",
      "           1       0.96      0.85      0.90       135\n",
      "           2       0.87      0.85      0.86        39\n",
      "           3       0.65      0.88      0.75        25\n",
      "           4       0.81      0.83      0.82        30\n",
      "           5       0.79      0.95      0.86        20\n",
      "           6       0.69      0.69      0.69        16\n",
      "           7       0.91      1.00      0.95        21\n",
      "\n",
      "    accuracy                           0.86       302\n",
      "   macro avg       0.83      0.87      0.85       302\n",
      "weighted avg       0.88      0.86      0.87       302\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_gen, val_gen, test_gen, class_weights = preproc_pipeline(desired_magnification='200X', \n",
    "                                                    image_resolution=(224, 224), \n",
    "                                                    classification_type='multiclass',\n",
    "                                                    use_data_augmentation=True,\n",
    "                                                    augmented_images_per_image=6)\n",
    "\n",
    "vgg16 = multiclass_classification_vgg16_model((224, 224, 3))\n",
    "\n",
    "fitted_vgg16 = train_model(train_gen, val_gen, vgg16, class_weights=class_weights, epochs=30, early_stopping_patience=5)\n",
    "\n",
    "get_classification_report(fitted_vgg16, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_classification_vgg16_model(input_shape):\n",
    "    \n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    \n",
    "    # train some layers and freeze others\n",
    "    for layer in base_model.layers[:-7]:\n",
    "        layer.trainable = False\n",
    "    for layer in base_model.layers[-7:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(base_model)\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "    \n",
    "    # low learning rate for fine tuning\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images before data augmentation: 1408\n",
      "Number of training images after data augmentation: 9856\n",
      "Epoch 1/30\n",
      "308/308 [==============================] - ETA: 0s - batch: 153.5000 - size: 32.0000 - loss: 2.0810 - accuracy: 0.1444"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vic\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training_v1.py:2332: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308/308 [==============================] - 177s 461ms/step - batch: 153.5000 - size: 32.0000 - loss: 2.0810 - accuracy: 0.1444 - val_loss: 1.9579 - val_accuracy: 0.2219\n",
      "Epoch 2/30\n",
      "308/308 [==============================] - 143s 463ms/step - batch: 153.5000 - size: 32.0000 - loss: 1.9442 - accuracy: 0.1763 - val_loss: 1.5821 - val_accuracy: 0.4205\n",
      "Epoch 3/30\n",
      "308/308 [==============================] - 128s 413ms/step - batch: 153.5000 - size: 32.0000 - loss: 1.4297 - accuracy: 0.3977 - val_loss: 1.3358 - val_accuracy: 0.4437\n",
      "Epoch 4/30\n",
      "308/308 [==============================] - 129s 417ms/step - batch: 153.5000 - size: 32.0000 - loss: 1.0566 - accuracy: 0.5172 - val_loss: 1.1213 - val_accuracy: 0.5099\n",
      "Epoch 5/30\n",
      "308/308 [==============================] - 131s 423ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.7952 - accuracy: 0.6024 - val_loss: 1.1534 - val_accuracy: 0.5662\n",
      "Epoch 6/30\n",
      "308/308 [==============================] - 130s 420ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.6300 - accuracy: 0.6784 - val_loss: 0.8735 - val_accuracy: 0.6755\n",
      "Epoch 7/30\n",
      "308/308 [==============================] - 135s 436ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.5332 - accuracy: 0.7302 - val_loss: 0.7653 - val_accuracy: 0.6954\n",
      "Epoch 8/30\n",
      "308/308 [==============================] - 134s 435ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.4620 - accuracy: 0.7562 - val_loss: 0.7424 - val_accuracy: 0.7550\n",
      "Epoch 9/30\n",
      "308/308 [==============================] - 132s 428ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.3693 - accuracy: 0.8071 - val_loss: 0.8016 - val_accuracy: 0.7053\n",
      "Epoch 10/30\n",
      "308/308 [==============================] - 133s 429ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.3124 - accuracy: 0.8316 - val_loss: 0.6074 - val_accuracy: 0.7881\n",
      "Epoch 11/30\n",
      "308/308 [==============================] - 131s 425ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.2864 - accuracy: 0.8511 - val_loss: 0.6703 - val_accuracy: 0.7815\n",
      "Epoch 12/30\n",
      "308/308 [==============================] - 130s 421ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.2622 - accuracy: 0.8600 - val_loss: 0.5759 - val_accuracy: 0.8212\n",
      "Epoch 13/30\n",
      "308/308 [==============================] - 143s 463ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.2244 - accuracy: 0.8823 - val_loss: 0.5274 - val_accuracy: 0.8808\n",
      "Epoch 14/30\n",
      "308/308 [==============================] - 139s 448ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.2322 - accuracy: 0.8889 - val_loss: 0.5104 - val_accuracy: 0.8311\n",
      "Epoch 15/30\n",
      "308/308 [==============================] - 136s 440ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.2113 - accuracy: 0.8893 - val_loss: 0.6472 - val_accuracy: 0.8212\n",
      "Epoch 16/30\n",
      "308/308 [==============================] - 139s 450ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.1776 - accuracy: 0.9084 - val_loss: 0.5702 - val_accuracy: 0.7947\n",
      "Epoch 17/30\n",
      "308/308 [==============================] - 135s 436ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.1446 - accuracy: 0.9249 - val_loss: 0.5789 - val_accuracy: 0.8510\n",
      "Epoch 18/30\n",
      "308/308 [==============================] - 137s 444ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.1597 - accuracy: 0.9229 - val_loss: 0.6637 - val_accuracy: 0.8113\n",
      "Epoch 19/30\n",
      "308/308 [==============================] - 174s 562ms/step - batch: 153.5000 - size: 32.0000 - loss: 0.1289 - accuracy: 0.9293 - val_loss: 0.7705 - val_accuracy: 0.8146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vic\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        16\n",
      "           1       0.91      0.79      0.84       135\n",
      "           2       0.91      0.77      0.83        39\n",
      "           3       0.57      0.68      0.62        25\n",
      "           4       0.83      0.80      0.81        30\n",
      "           5       0.54      0.95      0.69        20\n",
      "           6       0.71      0.94      0.81        16\n",
      "           7       0.86      0.90      0.88        21\n",
      "\n",
      "    accuracy                           0.81       302\n",
      "   macro avg       0.79      0.85      0.81       302\n",
      "weighted avg       0.84      0.81      0.82       302\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_gen, val_gen, test_gen, class_weights = preproc_pipeline(desired_magnification='200X', \n",
    "                                                    image_resolution=(224, 224), \n",
    "                                                    classification_type='multiclass',\n",
    "                                                    use_data_augmentation=True,\n",
    "                                                    augmented_images_per_image=6)\n",
    "\n",
    "vgg16 = multiclass_classification_vgg16_model((224, 224, 3))\n",
    "\n",
    "fitted_vgg16 = train_model(train_gen, val_gen, vgg16, class_weights=class_weights, epochs=30, early_stopping_patience=5)\n",
    "\n",
    "get_classification_report(fitted_vgg16, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen, val_gen, test_gen, class_weights = preproc_pipeline(desired_magnification='200X', \n",
    "                                                    image_resolution=(224, 224), \n",
    "                                                    classification_type='binary',\n",
    "                                                    use_data_augmentation=False,\n",
    "                                                    augmented_images_per_image=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NumpyArrayIterator' object has no attribute 'class_indices'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 216\u001b[0m\n\u001b[0;32m    212\u001b[0m     test_gen \u001b[38;5;241m=\u001b[39m datagen_clean_pass\u001b[38;5;241m.\u001b[39mflow(X_test, y_test, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m train_gen, val_gen, test_gen, class_weights\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtrain_gen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_indices\u001b[49m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NumpyArrayIterator' object has no attribute 'class_indices'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "def resize_and_append(image_path, label, X, y, img_size):\n",
    "    \"\"\"\n",
    "    Resize an image and append it along with its label to the provided lists.\n",
    "    \n",
    "    Parameters:\n",
    "        - image_path (str): The file path to the image to be resized.\n",
    "        - label (any): The label associated with the image.\n",
    "        - X (list): The list to which the resized image array will be appended.\n",
    "        - y (list): The list to which the label will be appended.\n",
    "        - img_size (tuple): The target size for resizing the image (width, height).\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    with Image.open(image_path) as img:\n",
    "        img_resized = img.resize(img_size)\n",
    "        img_array = np.array(img_resized)\n",
    "        \n",
    "        X.append(img_array)\n",
    "        y.append(label)\n",
    "    \n",
    "def label_encode(y_train, y_test, y_val):\n",
    "    \"\"\"\n",
    "    Encodes the labels of the training, testing, and validation datasets using label encoding.\n",
    "    \n",
    "    Parameters:\n",
    "        - y_train (array-like): The labels for the training dataset.\n",
    "        - y_test (array-like): The labels for the testing dataset.\n",
    "        - y_val (array-like): The labels for the validation dataset.\n",
    "        \n",
    "    Returns:\n",
    "        - y_train (numpy.ndarray): Encoded training set labels.\n",
    "        - y_test (numpy.ndarray): Encoded testing set labels.\n",
    "        - y_val (numpy.ndarray): Encoded validation set labels.\n",
    "    \"\"\"\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(y_train)\n",
    "    y_test = le.fit_transform(y_test)\n",
    "    y_val = le.fit_transform(y_val)\n",
    "        \n",
    "    return y_train, y_test, y_val\n",
    "\n",
    "def load_and_preprocess_data(csv_path, desired_magnification, image_resolution, label_column):\n",
    "    \"\"\"\n",
    "    Load and preprocess image data from the CSV file containing the image metadata.\n",
    "    This function reads image data paths and labels from the CSV file, filters the data based on the desired magnification,\n",
    "    resizes the images to the specified resolution, sorts the data into training, testing, and validation arrays.\n",
    "    The images are then normalized, and the labels are encoded.\n",
    "    \n",
    "    Parameters:\n",
    "        - csv_path (str): Path to the image metadata CSV.\n",
    "        - desired_magnification (int): The magnification level to filter the images (40X, 100X, 200X, 400X).\n",
    "        - image_resolution (tuple): The desired resolution to resize the images (width, height).\n",
    "        - label_column (str): The name of the column in the CSV file that contains the labels ('Benign or Malignant' or 'Cancer Type').\n",
    "        \n",
    "    Returns:\n",
    "        - X_train (numpy.ndarray): Training set images.\n",
    "        - y_train (numpy.ndarray): Training set labels.\n",
    "        - X_test (numpy.ndarray): Testing set images.\n",
    "        - y_test (numpy.ndarray): Testing set labels.\n",
    "        - X_val (numpy.ndarray): Validation set images.\n",
    "        - y_val (numpy.ndarray): Validation set labels.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # select only the rows for the selected magnification (40X, 100X, 200X, 400X)\n",
    "    df_filtered = df[df['Magnification'] == desired_magnification]\n",
    "    \n",
    "    X_train, y_train = [], []\n",
    "    X_test, y_test = [], []\n",
    "    X_val, y_val = [], []\n",
    "    \n",
    "    # it is necessary to use the updated_image_data.csv file to get the correct path to the images\n",
    "    for boda, row in df_filtered.iterrows():\n",
    "        image_path = row['path_to_image']\n",
    "        label = row[label_column]\n",
    "        if 'train' in image_path:\n",
    "            resize_and_append(image_path, label, X_train, y_train, image_resolution)\n",
    "        elif 'test' in image_path:\n",
    "            resize_and_append(image_path, label, X_test, y_test, image_resolution)\n",
    "        elif 'val' in image_path:\n",
    "            resize_and_append(image_path, label, X_val, y_val, image_resolution)\n",
    "            \n",
    "    # convert lists to numpy arrays\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "    X_val = np.array(X_val)\n",
    "    y_val = np.array(y_val)\n",
    "    \n",
    "    # label encode the target variable (use sparse_categorical_crossentropy as loss function for multiclass)\n",
    "    y_train, y_test, y_val = label_encode(y_train, y_test, y_val)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, X_val, y_val\n",
    "\n",
    "def data_augmentation(X_train, y_train, datagen, augmented_images_per_image):\n",
    "    \"\"\"\n",
    "    Perform data augmentation on the training dataset.\n",
    "    \n",
    "    Parameters:\n",
    "        - X_train (numpy.ndarray): Array of training images.\n",
    "        - y_train (numpy.ndarray): Array of training labels.\n",
    "        - datagen (ImageDataGenerator): Keras ImageDataGenerator instance for generating augmented images.\n",
    "        - augmented_images_per_image (int): Number of augmented images to generate per original image.\n",
    "        \n",
    "    Returns:\n",
    "        - X_train_augmented (numpy.ndarray): Array of augmented training images.\n",
    "        - y_train_augmented (numpy.ndarray): Array of augmented training labels.\n",
    "    \"\"\"\n",
    "    augmented_images = []\n",
    "    augmented_labels = []\n",
    "\n",
    "    # also include original images in the data augmentation\n",
    "    for i in range(len(X_train)):\n",
    "        augmented_images.append(X_train[i])\n",
    "        augmented_labels.append(y_train[i])\n",
    "\n",
    "    # generate augmented images\n",
    "    for i in range(len(X_train)):\n",
    "        x = X_train[i]\n",
    "        y = y_train[i]\n",
    "        x = x.reshape((1,) + x.shape) # datagen.flow expects 4D arrays, so we need to reshape the 3D array\n",
    "        boda = 0\n",
    "        for batch in datagen.flow(x, batch_size=1): # generate 1 augmented image per iteration\n",
    "            augmented_images.append(batch[0])\n",
    "            augmented_labels.append(y)\n",
    "            boda += 1\n",
    "            if boda >= augmented_images_per_image:\n",
    "                break\n",
    "\n",
    "    X_train_augmented = np.array(augmented_images)\n",
    "    y_train_augmented = np.array(augmented_labels)\n",
    "    \n",
    "    return X_train_augmented, y_train_augmented\n",
    "\n",
    "def preproc_pipeline(desired_magnification, \n",
    "                     image_resolution, \n",
    "                     classification_type='binary',\n",
    "                     use_data_augmentation=False,\n",
    "                     augmented_images_per_image=5,\n",
    "                     csv_path = 'image_metadata/updated_image_data.csv',\n",
    "                     batch_size=32):\n",
    "    \"\"\"\n",
    "    Preprocess image data.\n",
    "\n",
    "    This function loads image data from the CSV file containing image metadata, filters it based on the desired magnification,\n",
    "    resizes the images, normalizes pixel values, encodes labels, and optionally performs data augmentation on the training set.\n",
    "    It returns data generators for training and validation, as well as the test dataset and class weights.\n",
    "\n",
    "    Parameters:\n",
    "        - desired_magnification (int): The magnification level to filter the images (40X, 100X, 200X, 400X).\n",
    "        - image_resolution (tuple): The desired resolution to resize the images (width, height).\n",
    "        - classification_type (str, optional): The type of classification ('binary' or 'multiclass'). Defaults to 'binary'.\n",
    "        - use_data_augmentation (bool, optional): Whether to perform data augmentation on the training dataset. Defaults to False.\n",
    "        - augmented_images_per_image (int, optional): Number of augmented images to generate per original image. Defaults to 5.\n",
    "        - csv_path (str, optional): Path to the image metadata CSV file. Defaults to 'image_metadata/updated_image_data.csv'.\n",
    "        - batch_size (int, optional): The batch size for the data generators. Defaults to 32.\n",
    "\n",
    "    Returns:\n",
    "        - train_gen (Iterator): Data generator for the training dataset.\n",
    "        - val_gen (Iterator): Data generator for the validation dataset.\n",
    "        - test_gen (Iterator): Data generator for the test dataset.\n",
    "        - class_weights (dict): Dictionary of class weights to handle class imbalance.\n",
    "    \"\"\"\n",
    "    \n",
    "    if classification_type == 'binary':\n",
    "        label_column = 'Benign or Malignant'\n",
    "    else: \n",
    "        classification_type = 'multiclass'\n",
    "        label_column = 'Cancer Type'\n",
    "    \n",
    "    X_train, y_train, X_test, y_test, X_val, y_val = load_and_preprocess_data(csv_path, desired_magnification, image_resolution, label_column)\n",
    "    \n",
    "    datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    )\n",
    "    \n",
    "    if use_data_augmentation == True:\n",
    "        print(f'Number of training images before data augmentation: {len(X_train)}')\n",
    "        X_train, y_train = data_augmentation(X_train, y_train, datagen, augmented_images_per_image)\n",
    "        print(f'Number of training images after data augmentation: {len(X_train)}')\n",
    "    \n",
    "    # calculate class weights because our problem is unbalanced\n",
    "    # np.unique makes this work for both binary (Benign/Malignant) and multiclass classification (Cancer Type)\n",
    "    class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "    class_weights = {i: weight for i, weight in enumerate(class_weights)}\n",
    "\n",
    "    \n",
    "    # data augmentation generators\n",
    "    # shuffles the data so no need to shuffle the data before passing it to the generator\n",
    "    train_gen = datagen.flow(X_train, y_train, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # define a generator for the validation and test data (only rescale)\n",
    "    datagen_clean_pass = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    val_gen = datagen_clean_pass.flow(X_val, y_val, batch_size=batch_size, shuffle=True)\n",
    "    test_gen = datagen_clean_pass.flow(X_test, y_test, batch_size=batch_size)\n",
    "    \n",
    "    return train_gen, val_gen, test_gen, class_weights\n",
    "\n",
    "print(train_gen.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
