{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Tuning Notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda\n",
    "import tensorflow as tf\n",
    "\n",
    "def clear_gpu_memory():\n",
    "    device = cuda.get_current_device()\n",
    "    device.reset() # dump the memory contents to free up the memory (it accumulates over the session)\n",
    "    \n",
    "# CUDA (Nvidia GPU Computing)\n",
    "if len(tf.config.list_physical_devices('GPU')) > 0:\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    print(\"Num GPUs Available: \", len(gpus))\n",
    "    \n",
    "    clear_gpu_memory()\n",
    "    \n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "\n",
    "    tf.config.set_logical_device_configuration(\n",
    "    gpus[0], \n",
    "    [tf.config.LogicalDeviceConfiguration(memory_limit=8192)])  # limit to 4GB\n",
    "\n",
    "    tf.compat.v1.disable_eager_execution()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from src.models.models import *\n",
    "from src.utils.modeling import *\n",
    "from src.utils.preproc import *\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: d:\\deep_learning_project CWD: d:\\deep_learning_project\n"
     ]
    }
   ],
   "source": [
    "# because the utils in the src are designed to be run from the root of the project,\n",
    "# and by default jupyter runs from the notebook directory we need to change the working directory to the root\n",
    "\n",
    "def find_project_root(filename=\".git\"): # .git is located in the root of the project\n",
    "    current_dir = os.getcwd()\n",
    "    while current_dir != os.path.dirname(current_dir): # stops only when at the root (moves up 1 level each iteration)\n",
    "        if filename in os.listdir(current_dir):\n",
    "            return current_dir\n",
    "        current_dir = os.path.dirname(current_dir)\n",
    "\n",
    "project_root = find_project_root()\n",
    "os.chdir(project_root)  # change the working directory to the project root\n",
    "\n",
    "print(\"Project root:\", project_root, \"CWD:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Binary Classification Models Fine-Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Traditional**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pre-Trained**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VGG 16**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_classification_vgg16_model(input_shape):\n",
    "    \n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    \n",
    "    # train some layers and freeze others\n",
    "    for layer in base_model.layers[:-4]:\n",
    "        layer.trainable = False\n",
    "    for layer in base_model.layers[-4:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(base_model)\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # low learning rate for fine tuning\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "44/44 [==============================] - ETA: 0s - batch: 21.5000 - size: 32.0000 - loss: 0.6080 - accuracy: 0.6619"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vic\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training_v1.py:2332: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 58s 569ms/step - batch: 21.5000 - size: 32.0000 - loss: 0.6080 - accuracy: 0.6619 - val_loss: 0.5586 - val_accuracy: 0.6755\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - 17s 366ms/step - batch: 21.5000 - size: 32.0000 - loss: 0.4588 - accuracy: 0.7663 - val_loss: 0.3790 - val_accuracy: 0.8146\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - 16s 356ms/step - batch: 21.5000 - size: 32.0000 - loss: 0.4083 - accuracy: 0.8132 - val_loss: 0.5486 - val_accuracy: 0.7053\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - 17s 370ms/step - batch: 21.5000 - size: 32.0000 - loss: 0.2893 - accuracy: 0.8736 - val_loss: 0.2648 - val_accuracy: 0.8775\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - 16s 350ms/step - batch: 21.5000 - size: 32.0000 - loss: 0.3044 - accuracy: 0.8636 - val_loss: 0.2750 - val_accuracy: 0.8642\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - 16s 358ms/step - batch: 21.5000 - size: 32.0000 - loss: 0.2395 - accuracy: 0.8949 - val_loss: 0.2801 - val_accuracy: 0.8808\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - 16s 350ms/step - batch: 21.5000 - size: 32.0000 - loss: 0.2072 - accuracy: 0.9134 - val_loss: 0.2549 - val_accuracy: 0.9040\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - 16s 355ms/step - batch: 21.5000 - size: 32.0000 - loss: 0.1727 - accuracy: 0.9318 - val_loss: 0.3699 - val_accuracy: 0.8907\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - 17s 361ms/step - batch: 21.5000 - size: 32.0000 - loss: 0.2755 - accuracy: 0.8842 - val_loss: 0.2384 - val_accuracy: 0.9139\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - 16s 345ms/step - batch: 21.5000 - size: 32.0000 - loss: 0.1757 - accuracy: 0.9276 - val_loss: 0.2762 - val_accuracy: 0.8874\n",
      "Test loss:  0.41194572629073994\n",
      "Test accuracy:  0.8576159\n"
     ]
    }
   ],
   "source": [
    "if len(tf.config.list_physical_devices('GPU')) > 0:\n",
    "    clear_gpu_memory()\n",
    "\n",
    "train_gen, val_gen, X_test, y_test, class_weights = preproc_pipeline(desired_magnification='200X', \n",
    "                                                    image_resolution=(224, 224), \n",
    "                                                    classification_type='binary')\n",
    "\n",
    "vgg16 = binary_classification_vgg16_model((224, 224, 3))\n",
    "\n",
    "fitted_vgg16 = train_model(train_gen, val_gen, vgg16, class_weights=class_weights, epochs=10)\n",
    "\n",
    "test_loss, test_acc = fitted_vgg16.evaluate(X_test, y_test)\n",
    "print(f'Test loss: ', test_loss)\n",
    "print(f'Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_classification_vgg16_model(input_shape):\n",
    "    \n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    \n",
    "    # train some layers and freeze others\n",
    "    for layer in base_model.layers[:-4]:\n",
    "        layer.trainable = False\n",
    "    for layer in base_model.layers[-4:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(base_model)\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "    \n",
    "    # low learning rate for fine tuning\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "44/44 [==============================] - ETA: 0s - batch: 21.5000 - size: 32.0000 - loss: 2.1634 - accuracy: 0.1612"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vic\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training_v1.py:2332: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 55s 550ms/step - batch: 21.5000 - size: 32.0000 - loss: 2.1634 - accuracy: 0.1612 - val_loss: 1.8832 - val_accuracy: 0.2748\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - 16s 355ms/step - batch: 21.5000 - size: 32.0000 - loss: 1.8226 - accuracy: 0.3111 - val_loss: 1.8702 - val_accuracy: 0.3311\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - 16s 369ms/step - batch: 21.5000 - size: 32.0000 - loss: 1.6152 - accuracy: 0.3913 - val_loss: 1.4509 - val_accuracy: 0.4735\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - 16s 355ms/step - batch: 21.5000 - size: 32.0000 - loss: 1.4558 - accuracy: 0.4482 - val_loss: 1.2018 - val_accuracy: 0.5430\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - 16s 352ms/step - batch: 21.5000 - size: 32.0000 - loss: 1.2445 - accuracy: 0.5107 - val_loss: 1.3725 - val_accuracy: 0.4536\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - 16s 353ms/step - batch: 21.5000 - size: 32.0000 - loss: 1.1136 - accuracy: 0.5043 - val_loss: 1.4204 - val_accuracy: 0.4470\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - 16s 353ms/step - batch: 21.5000 - size: 32.0000 - loss: 1.0569 - accuracy: 0.5391 - val_loss: 1.4090 - val_accuracy: 0.4603\n",
      "Test loss:  1.0476425605893924\n",
      "Test accuracy:  0.5860927\n"
     ]
    }
   ],
   "source": [
    "if len(tf.config.list_physical_devices('GPU')) > 0:\n",
    "    clear_gpu_memory()\n",
    "\n",
    "train_gen, val_gen, X_test, y_test, class_weights = preproc_pipeline(desired_magnification='200X', \n",
    "                                                    image_resolution=(224, 224), \n",
    "                                                    classification_type='multiclass')\n",
    "\n",
    "vgg16 = multiclass_classification_vgg16_model((224, 224, 3))\n",
    "\n",
    "fitted_vgg16 = train_model(train_gen, val_gen, vgg16, class_weights=class_weights, epochs=10)\n",
    "\n",
    "test_loss, test_acc = fitted_vgg16.evaluate(X_test, y_test)\n",
    "print(f'Test loss: ', test_loss)\n",
    "print(f'Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
